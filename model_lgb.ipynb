{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting lightgbm\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/25/47/f8ef524e15ff86f5246cb4e1cee200b747ddb2536429fa021cc5f17ea40a/lightgbm-3.0.0-py2.py3-none-manylinux1_x86_64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 8.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from lightgbm) (1.18.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from lightgbm) (1.5.0)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from lightgbm) (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (0.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Collecting tables\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/ed/c3/8fd9e3bb21872f9d69eb93b3014c86479864cca94e625fd03713ccacec80/tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 8.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.3 in /opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages (from tables) (1.18.5)\n",
      "Collecting numexpr>=2.6.2\n",
      "  Downloading http://mirrors.tencentyun.com/pypi/packages/36/ed/eac5f6123f54a61cd13b7e89826b97edea54adf76d9f8e9fa2ce70e2fdf8/numexpr-2.7.1-cp36-cp36m-manylinux1_x86_64.whl (162 kB)\n",
      "\u001b[K     |████████████████████████████████| 162 kB 15.9 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numexpr, tables\n",
      "Successfully installed numexpr-2.7.1 tables-3.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.read_csv('test_data_B.csv',sep = '|')\n",
    "# test_data.to_hdf('test_data_B.h5', key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv('train_data.csv',sep = '|')\n",
    "# test_data = pd.read_csv('test_data_A.csv',sep = '|')\n",
    "# train_data.to_hdf('train_data.h5', key='data')\n",
    "# test_data.to_hdf('test_data.h5', key='data')\n",
    "train_data = pd.read_hdf('train_data.h5', key='data')\n",
    "test_data_A = pd.read_hdf('test_data.h5', key='data')\n",
    "test_data_B = pd.read_hdf('test_data_B.h5', key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_B['pt_d']-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([test_data_A,test_data_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000000, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['min_onlinerate'] = train_data['communication_onlinerate'].apply(lambda x:int(x.split('^')[0]))\n",
    "train_data['max_onlinerate'] = train_data['communication_onlinerate'].apply(lambda x:int(x.split('^')[-1]))\n",
    "test_data['min_onlinerate'] = test_data['communication_onlinerate'].apply(lambda x:int(x.split('^')[0]))\n",
    "test_data['max_onlinerate'] = test_data['communication_onlinerate'].apply(lambda x:int(x.split('^')[-1]))\n",
    "#0.764802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_data.groupby(['uid','pt_d']).agg({'label':'sum'}).reset_index()\n",
    "temp.columns = ['uid','pt_d','click_lastday_count']\n",
    "temp['pt_d']+=1\n",
    "test_data = test_data.merge(temp,on = ['uid','pt_d'],how = 'left')\n",
    "train_data = train_data.merge(temp,on = ['uid','pt_d'],how = 'left')\n",
    "#+0.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_data.groupby(['uid','pt_d']).agg({'adv_id':'count'}).reset_index()\n",
    "temp.columns = ['uid','pt_d','expo_lastday_counts']\n",
    "temp['pt_d']+=1\n",
    "test_data = test_data.merge(temp,on = ['uid','pt_d'],how = 'left')\n",
    "train_data = train_data.merge(temp,on = ['uid','pt_d'],how = 'left')\n",
    "#001 0.776932 - 0.758022   # +3.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = test_data.groupby(['uid','pt_d']).agg({'adv_id':'count'}).reset_index()\n",
    "temp.columns = ['uid','pt_d','expo_day_counts']\n",
    "test_data = test_data.merge(temp,on = ['uid','pt_d'],how = 'left')\n",
    "\n",
    "temp = train_data.groupby(['uid','pt_d']).agg({'adv_id':'count'}).reset_index()\n",
    "temp.columns = ['uid','pt_d','expo_day_counts']\n",
    "train_data = train_data.merge(temp,on = ['uid','pt_d'],how = 'left')\n",
    "#002 79 0.751055 +6%  +3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['expo_day_counts']*=3 #0.781291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 52,\n",
    "         'objective':'binary',\n",
    "         'learning_rate': 0.1,        \n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1,\n",
    "         \"num_threads\" : -1,\n",
    "#          'device': 'gpu',\n",
    "#          'gpu_platform_id': 0,\n",
    "#          'gpu_device_id': 0\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'uid', 'task_id', 'adv_id', 'creat_type_cd', 'adv_prim_id',\n",
       "       'dev_id', 'inter_type_cd', 'slot_id', 'spread_app_id', 'tags',\n",
       "       'app_first_class', 'app_second_class', 'age', 'city', 'city_rank',\n",
       "       'device_name', 'device_size', 'career', 'gender', 'net_type',\n",
       "       'residence', 'his_app_size', 'his_on_shelf_time', 'app_score',\n",
       "       'emui_dev', 'list_time', 'device_price', 'up_life_duration',\n",
       "       'up_membership_grade', 'membership_life_duration', 'consume_purchase',\n",
       "       'communication_onlinerate', 'communication_avgonline_30d', 'indu_name',\n",
       "       'pt_d', 'min_onlinerate', 'max_onlinerate', 'click_lastday_count',\n",
       "       'expo_lastday_counts', 'expo_day_counts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_col=['task_id', 'adv_id', 'creat_type_cd', 'adv_prim_id',\n",
    "       'dev_id', 'inter_type_cd', 'slot_id', 'spread_app_id', 'tags',\n",
    "       'app_first_class', 'app_second_class', 'age', 'city', 'city_rank',\n",
    "       'device_name', 'device_size', 'career', 'gender', 'net_type',\n",
    "       'residence', 'his_app_size', 'his_on_shelf_time', 'app_score',\n",
    "       'emui_dev', 'list_time', 'device_price', 'up_life_duration',\n",
    "       'up_membership_grade', 'membership_life_duration', 'consume_purchase',\n",
    "        'communication_avgonline_30d', 'indu_name',\n",
    "         'expo_day_counts','expo_lastday_counts','click_lastday_count','min_onlinerate','max_onlinerate',\n",
    "        ]# ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col=['task_id', 'adv_id', 'creat_type_cd', 'adv_prim_id',\n",
    "       'dev_id', 'inter_type_cd', 'slot_id', 'spread_app_id', 'tags',\n",
    "       'app_first_class', 'app_second_class', 'city', 'city_rank',\n",
    "       'device_name', 'device_size', 'career', 'gender', 'net_type',\n",
    "       'residence', 'his_app_size', 'his_on_shelf_time', 'app_score',\n",
    "       'emui_dev', 'list_time', 'device_price', 'up_life_duration',\n",
    "       'up_membership_grade', 'membership_life_duration', 'consume_purchase',\n",
    "        'communication_avgonline_30d', 'indu_name']# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data['label']\n",
    "train_data = train_data[all_col]\n",
    "test_data = test_data[all_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold,GroupKFold,RepeatedKFold\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "stack_test = np.zeros((len(test_data.iloc[1000000:]),1))\n",
    "stack_train = np.zeros((len(train_data),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/envs/tensorflow_py3/lib/python3.6/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's auc: 0.802754\tvalid_1's auc: 0.799858\n",
      "[100]\ttraining's auc: 0.807458\tvalid_1's auc: 0.8011\n",
      "[150]\ttraining's auc: 0.810451\tvalid_1's auc: 0.801404\n",
      "[200]\ttraining's auc: 0.812894\tvalid_1's auc: 0.801531\n",
      "[250]\ttraining's auc: 0.815069\tvalid_1's auc: 0.801624\n",
      "[300]\ttraining's auc: 0.816914\tvalid_1's auc: 0.801628\n",
      "[350]\ttraining's auc: 0.818612\tvalid_1's auc: 0.801559\n",
      "Early stopping, best iteration is:\n",
      "[287]\ttraining's auc: 0.816429\tvalid_1's auc: 0.801643\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's auc: 0.80283\tvalid_1's auc: 0.799345\n",
      "[100]\ttraining's auc: 0.807449\tvalid_1's auc: 0.800652\n",
      "[150]\ttraining's auc: 0.810373\tvalid_1's auc: 0.800956\n",
      "[200]\ttraining's auc: 0.812885\tvalid_1's auc: 0.801117\n",
      "[250]\ttraining's auc: 0.815096\tvalid_1's auc: 0.801198\n",
      "[300]\ttraining's auc: 0.817051\tvalid_1's auc: 0.801183\n",
      "[350]\ttraining's auc: 0.818713\tvalid_1's auc: 0.801171\n",
      "Early stopping, best iteration is:\n",
      "[254]\ttraining's auc: 0.815255\tvalid_1's auc: 0.801205\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's auc: 0.802672\tvalid_1's auc: 0.799586\n",
      "[100]\ttraining's auc: 0.807427\tvalid_1's auc: 0.800834\n",
      "[150]\ttraining's auc: 0.81047\tvalid_1's auc: 0.801169\n",
      "[200]\ttraining's auc: 0.812918\tvalid_1's auc: 0.801293\n",
      "[250]\ttraining's auc: 0.815099\tvalid_1's auc: 0.801364\n",
      "[300]\ttraining's auc: 0.817041\tvalid_1's auc: 0.801353\n",
      "[350]\ttraining's auc: 0.818843\tvalid_1's auc: 0.801372\n",
      "[400]\ttraining's auc: 0.82044\tvalid_1's auc: 0.801306\n",
      "Early stopping, best iteration is:\n",
      "[314]\ttraining's auc: 0.817612\tvalid_1's auc: 0.801376\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's auc: 0.802859\tvalid_1's auc: 0.79891\n",
      "[100]\ttraining's auc: 0.807619\tvalid_1's auc: 0.80025\n",
      "[150]\ttraining's auc: 0.810539\tvalid_1's auc: 0.800603\n",
      "[200]\ttraining's auc: 0.813111\tvalid_1's auc: 0.800725\n",
      "[250]\ttraining's auc: 0.815308\tvalid_1's auc: 0.800796\n",
      "[300]\ttraining's auc: 0.817214\tvalid_1's auc: 0.800819\n",
      "[350]\ttraining's auc: 0.818993\tvalid_1's auc: 0.800834\n",
      "[400]\ttraining's auc: 0.820573\tvalid_1's auc: 0.800792\n",
      "Early stopping, best iteration is:\n",
      "[341]\ttraining's auc: 0.81872\tvalid_1's auc: 0.800845\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttraining's auc: 0.802572\tvalid_1's auc: 0.799828\n",
      "[100]\ttraining's auc: 0.807191\tvalid_1's auc: 0.8011\n",
      "[150]\ttraining's auc: 0.810224\tvalid_1's auc: 0.801394\n",
      "[200]\ttraining's auc: 0.812727\tvalid_1's auc: 0.801516\n",
      "[250]\ttraining's auc: 0.814935\tvalid_1's auc: 0.801586\n",
      "[300]\ttraining's auc: 0.816842\tvalid_1's auc: 0.801551\n",
      "[350]\ttraining's auc: 0.818714\tvalid_1's auc: 0.801568\n",
      "Early stopping, best iteration is:\n",
      "[260]\ttraining's auc: 0.815369\tvalid_1's auc: 0.801592\n"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_data, target)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_data.iloc[trn_idx],\n",
    "                           label=target[trn_idx],\n",
    "                           categorical_feature=cat_col\n",
    "                           )\n",
    "    val_data = lgb.Dataset(train_data.iloc[val_idx],\n",
    "                           label=target[val_idx],\n",
    "                           categorical_feature=cat_col\n",
    "                           )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=50,\n",
    "                    early_stopping_rounds=100)\n",
    "    stack_train[val_idx, :] =clf.predict(train_data.iloc[val_idx], num_iteration=clf.best_iteration).reshape(-1,1)\n",
    "    stack_test += clf.predict(test_data.iloc[1000000:], num_iteration=clf.best_iteration).reshape(-1,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_train = pd.DataFrame(stack_train)\n",
    "oof_test = pd.DataFrame(stack_test/5)\n",
    "pd.concat([oof_train,oof_test]).to_hdf('lgboof.h5', key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "feature_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df[\"feature\"] = all_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_importance_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-597778b02101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_importance_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'importance'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_importance_df' is not defined"
     ]
    }
   ],
   "source": [
    "feature_importance_df.sort_values('importance',ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
